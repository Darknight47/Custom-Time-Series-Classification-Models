{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Custom Fully Convolutional Networks For Time Series Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Three Different Time Series Datasets by using sktime's `load_UCR_UEA_dataset` \n",
    "#### About the datasets:\n",
    "* First dataset is called **DistalPhalanxOutlineCorrect**. It has 2 classes, It is of type Image, and it has one dimension.\n",
    "* Second dataset is called **ItalyPowerDemand**. It has 2 classes, It is of type Sensor, and it has one dimension.\n",
    "* Third dataset is called **BME**. It has 3 classes, It is of type Simulated, and it has one dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Importing necessary packages!\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# load_UCR_UEA_dataset\n",
    "from sktime.datasets import load_UCR_UEA_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Importing Time Series Datasets!\n",
    "# 2 Classes, 1D, Image\n",
    "X_train_1, y_train_1 = load_UCR_UEA_dataset(name=\"DistalPhalanxOutlineCorrect\", split=\"train\", return_type=\"numpy2D\")\n",
    "X_test_1, y_test_1 = load_UCR_UEA_dataset(name=\"DistalPhalanxOutlineCorrect\", split=\"test\", return_type=\"numpy2D\")\n",
    "\n",
    "# 2 Classes, 1D, Sensor \n",
    "X_train_2, y_train_2 = load_UCR_UEA_dataset(name= \"ItalyPowerDemand\", split=\"train\", return_type=\"numpy2D\")\n",
    "X_test_2, y_test_2 = load_UCR_UEA_dataset(name=\"ItalyPowerDemand\", split=\"test\", return_type=\"numpy2D\")\n",
    "\n",
    "# 3Classes, 1D, Simulated\n",
    "X_train_3, y_train_3 = load_UCR_UEA_dataset(name = \"BME\", split=\"train\", return_type=\"numpy2D\")\n",
    "X_test_3, y_test_3 = load_UCR_UEA_dataset(name = \"BME\", split=\"test\", return_type=\"numpy2D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1: (600, 80) (276, 80)\n",
      "Dataset 2: (67, 24) (1029, 24)\n",
      "Dataset 3: (30, 128) (150, 128)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset 1:\", X_train_1.shape, X_test_1.shape)\n",
    "print(\"Dataset 2:\", X_train_2.shape, X_test_2.shape)\n",
    "print(\"Dataset 3:\", X_train_3.shape, X_test_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different datasets, which means we must have a function that can take in different datasets with different length.  \n",
    "\n",
    "The plain baseline is a **Fully Convolutional Networks** which is build by stacking three convolution blocks with the filter sizes {128,256, 128} in each block.  \n",
    "* Unlike the MCNN and MC-CNN, We exclude any pooling operation.  \n",
    "* The basic block is a convolutional layer followed by a batch normalization layer and a ReLU activation layer.  \n",
    "* The convolution operation is fulfilled by three 1-D kernels with the sizes {8, 5, 3} without striding.\n",
    "* Batch normalization is applied to speed up the convergence speed and help improve generalization. \n",
    "* After the convolution blocks, the features are fed into a global average pooling layer instead of a fully connected layer, which largely reduces the number of weights. The final label is produced by a softmax layer\n",
    "\n",
    "\n",
    "The FCN Model is then trained with **Adam** with learning rate 0.001, ρ = 0.9, β1 = 0.9, β2 = 0.999 and e = 1e − 8!  \n",
    "\n",
    "The loss function for the model is **categorical cross entropy**! With **accuracy** as metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are having different dataset with different types and sizes!\n",
    "def create_fcn_model(input_shape, num_classes):\n",
    "    fcn_model = tf.keras.Sequential([\n",
    "        keras.layers.Conv1D(filters=128, kernel_size=8, input_shape=input_shape),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Conv1D(filters=256, kernel_size=5),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Conv1D(filters=128, kernel_size=3),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.GlobalAveragePooling1D(),\n",
    "        keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "    fcn_model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.001, epsilon=1e-8),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return fcn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining **callbacks** parameters for fine tuning!  \n",
    "Defining **label encoder** for converting data to numerical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
